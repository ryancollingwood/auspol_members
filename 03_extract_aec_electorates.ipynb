{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AEC Localitites\n",
    "\n",
    "The Australian Electoral Commission websites has a page where you can search for localities by postcode or electorate.\n",
    "\n",
    "We will scrape these pages for every electorate in the representives we exported from theyvoteforyou.org.au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 88.0.4324\n",
      "[WDM] - Get LATEST driver version for 88.0.4324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Get LATEST driver version for 88.0.4324\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/88.0.4324.96/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\ryanc\\.wdm\\drivers\\chromedriver\\win32\\88.0.4324.96]\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Representatives\n",
    "\n",
    "Then get the unique electorates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "representatives_df = pd.read_csv(\"02_transform_they_vote_for_you/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "electorates = list(representatives_df[\"electorate\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function for getting a url for a specific electorate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_electorate_url(electorate):\n",
    "    return f'https://electorate.aec.gov.au/LocalitySearchResults.aspx?filter={electorate}&filterby=Electorate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating to Page and Dealing with Pagnation\n",
    "\n",
    "Import to have a sleep between requests so we don't deny-listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_pages(df):\n",
    "    # get the maximum number of pages\n",
    "    pages_df = df.T\n",
    "    pages_df.columns = [\"pages\"]\n",
    "    pages_df[\"pages\"] = pd.to_numeric(pages_df[\"pages\"], errors =\"coerce\")\n",
    "    \n",
    "    more_pages = any(pages_df[\"pages\"].isnull())\n",
    "    \n",
    "    try:\n",
    "        max_pages = pages_df[\"pages\"].max()\n",
    "    except:\n",
    "        max_pages = None\n",
    "        \n",
    "    return max_pages, more_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_data(browser, for_page, do_pagination = False):\n",
    "    \n",
    "    if do_pagination:\n",
    "        print(\"\\tpaging to get additional results\")\n",
    "    \n",
    "    print(f\"\\tgetting page {for_page}\")\n",
    "\n",
    "    if do_pagination or for_page > 1:\n",
    "        try:\n",
    "            # first look at how many links we get back because in the case of \n",
    "            # \"...\" we might get two let's assume the the last item \n",
    "            # we get is the one we want\n",
    "            \n",
    "            link_text = str(for_page)\n",
    "            if do_pagination:\n",
    "                link_text = \"...\"\n",
    "            \n",
    "            found_links = browser.links.find_by_text(link_text)\n",
    "            found_links[-1].click()\n",
    "                        \n",
    "            sleep(0.5)\n",
    "            \n",
    "        except ElementDoesNotExist:\n",
    "            return None, None, None\n",
    "\n",
    "    # extract pages from browser html\n",
    "    tables = pd.read_html(browser.html)\n",
    "\n",
    "    max_pages, more_pages = get_max_pages(tables[1])\n",
    "    \n",
    "    if max_pages == for_page:\n",
    "        more_pags = False    \n",
    "    \n",
    "    # this occurs when we've attempted to paginate by clicking on \"...\"\n",
    "    # but it takes us backwards, so we've likely got all of the pages\n",
    "    if max_pages < for_page:\n",
    "        print(f\"\\tWe have navigated backwards: max_pages: {max_pages} last page: {for_page}\")\n",
    "        return None, None, None        \n",
    "    \n",
    "    return tables[0], max_pages, more_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this bit of code could do with some refatoring as there's a lot of repeated logic. Part of the challenge is we're having to step through multiple sub-pages and finding out if there are more pages due to the \"...\" link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_electorate_data(electorate):   \n",
    "    destination_file = f\"03_extract_aec_electorates/{electorate.lower()}.csv\"\n",
    "    \n",
    "    if os.path.exists(destination_file):\n",
    "        print(f\"{electorate} - skipping file already exists\")\n",
    "        return\n",
    "    \n",
    "    url = get_electorate_url(electorate)\n",
    "    \n",
    "    print(f\"{electorate} - {url}\")\n",
    "\n",
    "    # list for storing the localities\n",
    "    locality_dfs = list()\n",
    "\n",
    "    # first navigate to page\n",
    "    browser.visit(url)\n",
    "    sleep(1)\n",
    "    \n",
    "    # counter for the current page\n",
    "    current_page = 1\n",
    "    \n",
    "    # the result of this is a list of dataframes\n",
    "    # the first being the locality data (electorate / postcode)\n",
    "    # the second being the number of pages\n",
    "    tables = pd.read_html(browser.html)\n",
    "\n",
    "    # get the page data, the maximum number of pages, and\n",
    "    # if there are more pages\n",
    "    page_df, max_pages, more_pages = get_page_data(browser, current_page)\n",
    "    \n",
    "    print(f\"\\tmax pages: {max_pages} - more pages: {more_pages}\")\n",
    "\n",
    "    # get the first locality data\n",
    "    locality_dfs.append(page_df)\n",
    "    \n",
    "    while current_page != max_pages:\n",
    "        current_page += 1\n",
    "        \n",
    "        page_df, max_pages, more_pages = get_page_data(browser, current_page)\n",
    "        if page_df is None:\n",
    "            print(f\"\\tCouldn't find a link to click {current_page}\")\n",
    "            break\n",
    "        \n",
    "        locality_dfs.append(page_df)\n",
    "        \n",
    "        if current_page == max_pages and more_pages:\n",
    "            # because pagination takes us to the next page\n",
    "            # increment our current_page\n",
    "            current_page += 1\n",
    "            page_df, max_pages, more_pages = get_page_data(browser, current_page, True)\n",
    "            \n",
    "            # in this case we have probably click the \"...\" link to go backwards\n",
    "            if page_df is None:\n",
    "                break\n",
    "            \n",
    "            print(f\"\\tmax pages: {max_pages} - more pages: {more_pages}\")            \n",
    "            locality_dfs.append(page_df)\n",
    "            \n",
    "\n",
    "    electorate_df = pd.concat(locality_dfs)\n",
    "    electorate_df.to_csv(destination_file, index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grayndler - skipping file already exists\n",
      "Menzies - skipping file already exists\n",
      "Cunningham - skipping file already exists\n",
      "Watson - skipping file already exists\n",
      "Holt - skipping file already exists\n",
      "Blaxland - skipping file already exists\n",
      "Franklin - skipping file already exists\n",
      "Isaacs - skipping file already exists\n",
      "Dickson - skipping file already exists\n",
      "Richmond - skipping file already exists\n",
      "Hunter - skipping file already exists\n",
      "Mitchell - skipping file already exists\n",
      "Flinders - skipping file already exists\n",
      "Swan - skipping file already exists\n",
      "Ballarat - https://electorate.aec.gov.au/LocalitySearchResults.aspx?filter=Ballarat&filterby=Electorate\n",
      "\tgetting page 1\n",
      "\tmax pages: 5.0 - more pages: True\n",
      "\tgetting page 2\n",
      "\tgetting page 3\n",
      "\tgetting page 4\n",
      "\tgetting page 5\n",
      "\tpaging to get additional results\n",
      "\tgetting page 6\n",
      "\tmax pages: 10.0 - more pages: True\n",
      "\tgetting page 7\n",
      "\tgetting page 8\n",
      "\tgetting page 9\n",
      "\tgetting page 10\n",
      "\tpaging to get additional results\n",
      "\tgetting page 11\n",
      "\tWe have navigated backwards: max_pages: 5.0 last page: 11\n",
      "Bowman - skipping file already exists\n",
      "Farrer - skipping file already exists\n",
      "Forrest - skipping file already exists\n",
      "Corio - skipping file already exists\n",
      "Cook - skipping file already exists\n",
      "Blair - skipping file already exists\n",
      "Gorton - skipping file already exists\n",
      "Parramatta - skipping file already exists\n",
      "Moreton - skipping file already exists\n",
      "Sydney - skipping file already exists\n",
      "Grey - skipping file already exists\n",
      "Kingston - skipping file already exists\n",
      "Fadden - skipping file already exists\n",
      "Maribyrnong - skipping file already exists\n",
      "Lingiari - skipping file already exists\n",
      "Calwell - skipping file already exists\n",
      "Makin - skipping file already exists\n",
      "Gippsland - skipping file already exists\n",
      "Bradfield - skipping file already exists\n",
      "Dawson - skipping file already exists\n",
      "Flynn - skipping file already exists\n",
      "Forde - skipping file already exists\n",
      "Hasluck - skipping file already exists\n",
      "Leichhardt - skipping file already exists\n",
      "McEwen - skipping file already exists\n",
      "Melbourne - skipping file already exists\n",
      "Kooyong - skipping file already exists\n",
      "Wannon - skipping file already exists\n",
      "Riverina - skipping file already exists\n",
      "Fowler - skipping file already exists\n",
      "McPherson - skipping file already exists\n",
      "Aston - https://electorate.aec.gov.au/LocalitySearchResults.aspx?filter=Aston&filterby=Electorate\n",
      "\tgetting page 1\n",
      "\tmax pages: nan - more pages: True\n",
      "\tgetting page 2\n",
      "\tCouldn't find a link to click 2\n",
      "Chifley - skipping file already exists\n",
      "Hughes - skipping file already exists\n",
      "Greenway - skipping file already exists\n",
      "McMahon - skipping file already exists\n",
      "Wright - skipping file already exists\n",
      "Bonner - skipping file already exists\n",
      "Banks - https://electorate.aec.gov.au/LocalitySearchResults.aspx?filter=Banks&filterby=Electorate\n",
      "\tgetting page 1\n",
      "\tmax pages: 2 - more pages: False\n",
      "\tgetting page 2\n",
      "Barker - https://electorate.aec.gov.au/LocalitySearchResults.aspx?filter=Barker&filterby=Electorate\n",
      "\tgetting page 1\n",
      "\tmax pages: 5.0 - more pages: True\n",
      "\tgetting page 2\n",
      "\tgetting page 3\n",
      "\tgetting page 4\n",
      "\tgetting page 5\n",
      "\tpaging to get additional results\n",
      "\tgetting page 6\n",
      "\tmax pages: 10.0 - more pages: True\n",
      "\tgetting page 7\n",
      "\tgetting page 8\n",
      "\tgetting page 9\n",
      "\tgetting page 10\n",
      "\tpaging to get additional results\n",
      "\tgetting page 11\n",
      "\tmax pages: 15.0 - more pages: True\n",
      "\tgetting page 12\n",
      "\tgetting page 13\n",
      "\tgetting page 14\n",
      "\tgetting page 15\n",
      "\tpaging to get additional results\n",
      "\tgetting page 16\n",
      "\tmax pages: 20.0 - more pages: True\n",
      "\tgetting page 17\n",
      "\tgetting page 18\n",
      "\tgetting page 19\n",
      "\tgetting page 20\n",
      "\tpaging to get additional results\n",
      "\tgetting page 21\n",
      "\tmax pages: 23.0 - more pages: True\n",
      "\tgetting page 22\n",
      "\tgetting page 23\n",
      "\tpaging to get additional results\n",
      "\tgetting page 24\n",
      "\tWe have navigated backwards: max_pages: 20.0 last page: 24\n",
      "Bendigo - skipping file already exists\n",
      "Capricornia - skipping file already exists\n",
      "Deakin - skipping file already exists\n",
      "Durack - skipping file already exists\n",
      "Gellibrand - skipping file already exists\n",
      "Hinkler - skipping file already exists\n",
      "Hotham - skipping file already exists\n",
      "Hume - skipping file already exists\n",
      "Kingsford Smith - skipping file already exists\n",
      "La Trobe - skipping file already exists\n",
      "Lalor - skipping file already exists\n",
      "Lyne - skipping file already exists\n",
      "Moore - skipping file already exists\n",
      "Newcastle - skipping file already exists\n",
      "O'Connor - skipping file already exists\n",
      "Page - skipping file already exists\n",
      "Pearce - skipping file already exists\n",
      "Petrie - skipping file already exists\n",
      "Rankin - skipping file already exists\n",
      "Robertson - skipping file already exists\n",
      "Scullin - skipping file already exists\n",
      "Griffith - skipping file already exists\n",
      "Casey - skipping file already exists\n",
      "Canning - skipping file already exists\n",
      "North Sydney - skipping file already exists\n",
      "Barton - https://electorate.aec.gov.au/LocalitySearchResults.aspx?filter=Barton&filterby=Electorate\n",
      "\tgetting page 1\n",
      "\tmax pages: 2 - more pages: False\n",
      "\tgetting page 2\n",
      "Burt - skipping file already exists\n",
      "Cowan - skipping file already exists\n",
      "Dobell - skipping file already exists\n",
      "Fairfax - skipping file already exists\n",
      "Lyons - skipping file already exists\n",
      "Macarthur - skipping file already exists\n",
      "Macquarie - skipping file already exists\n",
      "Paterson - skipping file already exists\n",
      "Solomon - skipping file already exists\n",
      "Mackellar - skipping file already exists\n",
      "Oxley - skipping file already exists\n",
      "Brisbane - skipping file already exists\n",
      "Boothby - skipping file already exists\n",
      "Calare - skipping file already exists\n",
      "Brand - skipping file already exists\n",
      "Bruce - skipping file already exists\n",
      "Shortland - skipping file already exists\n",
      "Tangney - skipping file already exists\n",
      "Wills - skipping file already exists\n",
      "Berowra - skipping file already exists\n",
      "Maranoa - skipping file already exists\n",
      "Wide Bay - skipping file already exists\n",
      "Goldstein - skipping file already exists\n",
      "Werriwa - skipping file already exists\n",
      "Fisher - skipping file already exists\n",
      "Fenner - skipping file already exists\n",
      "Whitlam - skipping file already exists\n",
      "Parkes - skipping file already exists\n",
      "Kennedy - skipping file already exists\n",
      "New England - skipping file already exists\n",
      "Bennelong - skipping file already exists\n",
      "Perth - skipping file already exists\n",
      "Mayo - skipping file already exists\n",
      "Fremantle - skipping file already exists\n",
      "Bass - https://electorate.aec.gov.au/LocalitySearchResults.aspx?filter=Bass&filterby=Electorate\n",
      "\tgetting page 1\n",
      "\tmax pages: 5.0 - more pages: True\n",
      "\tgetting page 2\n",
      "\tgetting page 3\n",
      "\tgetting page 4\n",
      "\tgetting page 5\n",
      "\tpaging to get additional results\n",
      "\tgetting page 6\n",
      "\tmax pages: 8.0 - more pages: True\n",
      "\tgetting page 7\n",
      "\tgetting page 8\n",
      "\tpaging to get additional results\n",
      "\tgetting page 9\n",
      "\tWe have navigated backwards: max_pages: 5.0 last page: 9\n",
      "Braddon - skipping file already exists\n",
      "Canberra - skipping file already exists\n",
      "Chisholm - skipping file already exists\n",
      "Corangamite - skipping file already exists\n",
      "Cowper - skipping file already exists\n",
      "Curtin - skipping file already exists\n",
      "Dunkley - skipping file already exists\n",
      "Fraser - skipping file already exists\n",
      "Gilmore - skipping file already exists\n",
      "Herbert - skipping file already exists\n",
      "Higgins - skipping file already exists\n",
      "Indi - skipping file already exists\n",
      "Jagajaga - skipping file already exists\n",
      "Lilley - skipping file already exists\n",
      "Lindsay - skipping file already exists\n",
      "Longman - skipping file already exists\n",
      "Macnamara - skipping file already exists\n",
      "Mallee - skipping file already exists\n",
      "Moncrieff - skipping file already exists\n",
      "Reid - skipping file already exists\n",
      "Ryan - skipping file already exists\n",
      "Stirling - skipping file already exists\n",
      "Sturt - skipping file already exists\n",
      "Warringah - skipping file already exists\n",
      "Wentworth - skipping file already exists\n",
      "Adelaide - https://electorate.aec.gov.au/LocalitySearchResults.aspx?filter=Adelaide&filterby=Electorate\n",
      "\tgetting page 1\n",
      "\tmax pages: 4 - more pages: False\n",
      "\tgetting page 2\n",
      "\tgetting page 3\n",
      "\tgetting page 4\n",
      "Monash - skipping file already exists\n",
      "Hindmarsh - skipping file already exists\n",
      "Spence - skipping file already exists\n",
      "Clark - skipping file already exists\n",
      "Nicholls - skipping file already exists\n",
      "Cooper - skipping file already exists\n",
      "Bean - https://electorate.aec.gov.au/LocalitySearchResults.aspx?filter=Bean&filterby=Electorate\n",
      "\tgetting page 1\n",
      "\tmax pages: 4 - more pages: False\n",
      "\tgetting page 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgetting page 3\n",
      "\tgetting page 4\n",
      "Eden-Monaro - skipping file already exists\n",
      "Groom - skipping file already exists\n"
     ]
    }
   ],
   "source": [
    "for electorate in electorates:\n",
    "    save_electorate_data(electorate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python38264bitpythondatacondad75933a419364c33a0623b6a6469479d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
